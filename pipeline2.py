# -*- coding: utf-8 -*-
"""pipeline2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OQRhybAG8EmgpzCfem_qdRTDm0hbPaXA

**Pipeline for using the model I trained, seperating noise and extracting real cells.**

In this notebook, the coordinates of cells saved in csv file are being used and by applying the trained model,
it will seperate the noise from the real cells and extracting them.
This is the second version of pipeline2 where the code is updated to take in more than one csv and produce
predictions of more than one csv of coordinates.
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import time, os, sys
from urllib.parse import urlparse
import skimage.io
import matplotlib.pyplot as plt
import matplotlib as mpl

# %matplotlib inline
mpl.rcParams['figure.dpi'] = 300
from urllib.parse import urlparse
from cellpose import models, core
use_GPU = core.use_gpu()
print('>>> GPU activated? %d'%use_GPU)
# call logger_setup to have output of cellpose written
from cellpose.io import logger_setup
logger_setup();

#IMPORTS
from tifffile import imread, imwrite   #read the svs image
from PIL import Image
import numpy as np    #numpy
import pandas as pd
import tensorflow as tf
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.applications.resnet50 import preprocess_input
from tensorflow.keras.layers import Input, Lambda
from tensorflow.keras.models import Model, load_model
from PIL import Image
from skimage.color import rgb2gray    #turn image to grayscale
from cellpose import models
from cellpose import plot
from cellpose import transforms
from cellpose import utils
import matplotlib.patches as patches
import csv
import random

#Special imports tp read the configuration file
import sys
sys.path.append("C:/Users/user/Documents/Hilsia_Rivka/Dream/MSc/research/usefulNotebooks/finals")
#import the configuration file
import pipelines_config_v2 as config
p = config.p


# Get the WSI image path and output directory dynamically
if len(sys.argv) < 3:
    raise ValueError("Usage: python pipeline2_v3.py <wsi_image_path> <output_dir>")

wsi_img_path = sys.argv[1]  # WSI image path
output_dir = sys.argv[2]    # Output directory

#Ensure output directory exists
os.makedirs(output_dir, exist_ok=True)


#Function to read the image
def readIMG(path):
  #my computer can read only up to size about 10M
  img = imread(path)
  return img

#Feature selection function
def select_top_k_features_tf(features, k_percent, k_final):
    # Compute the L2 norm of each feature across the batch
    norm = tf.norm(features, axis=0)
    # Get the indices of the top k_percent features
    num_top_percent = int(features.shape[-1] * k_percent)
    top_percent_indices = tf.argsort(norm, direction='DESCENDING')[:num_top_percent]
    top_percent_features = tf.gather(features, top_percent_indices, axis=1)
    # Compute the L2 norm again for the top k_percent features
    norm_top_percent = tf.norm(top_percent_features, axis=0)
    # Get the indices of the top k_final features within the top k_percent
    top_k_final_indices = tf.argsort(norm_top_percent, direction='DESCENDING')[:k_final]
    # Gather the top k_final features from the top k_percent features
    top_k_final_features = tf.gather(top_percent_features, top_k_final_indices, axis=1)
    return top_k_final_features

# Define the percentages and final number of features
k_percent = p["k_percent"]  # Select top 20% initially, #from configuration file
k_final = p["k_final"]     # Then select 51 features from those, #from configuration file

#Load ResNet50 model pre-trained on ImageNet without the top layer
base_model = ResNet50(weights='imagenet', include_top=False, pooling='avg')

# Input shape for the new model
input_shape = (224, 224, 3)
input_tensor = Input(shape=input_shape)
features = base_model(input_tensor)
# Create the final model
feature_extraction_model = Model(inputs=input_tensor, outputs=features)

# Load your existing dense model
existing_model_path = p["existing_model_path"]    #from configuration file
existing_model = load_model(existing_model_path)

# Function to load and crop image sections based on CSV coordinates
def load_and_crop_image(wsi_im, ymin, ymax, xmin, xmax, target_size=(224, 224)):
    # Check if the coordinates are valid and result in a non-zero crop
    if ymin >= ymax or xmin >= xmax:
        print(f"Invalid coordinates: ymin={ymin}, ymax={ymax}, xmin={xmin}, xmax={xmax}")
        return np.zeros((target_size[0], target_size[1], 3), dtype=np.uint8)
    else:
        img_cropped = wsi_im[ymin:ymax, xmin:xmax, :]
        img_resized = tf.image.resize(img_cropped, target_size)
        img_array = img_to_array(img_resized.numpy())
        return preprocess_input(img_array)

# Function to process images based on coordinates from a CSV
def process_images_from_csv(csv_path, wsi_im, batch_size, real_cells_dest):
    data = pd.read_csv(csv_path)
    real_cells = []

    for start_idx in range(0, len(data), batch_size):
        batch_data = data.iloc[start_idx:start_idx + batch_size]
        batch_images = []
        batch_coords = []
        # Extract and preprocess each specified region
        for _, row in batch_data.iterrows():
            x_min, x_max, y_min, y_max = row['min x'], row['max x'], row['min y'], row['max y']
            img = load_and_crop_image(wsi_im, y_min, y_max, x_min, x_max)
            batch_images.append(img)
            batch_coords.append([x_min, x_max, y_min, y_max])
        batch_images = np.array(batch_images)
        batch_features = feature_extraction_model.predict(batch_images)
        batch_selected_features = select_top_k_features_tf(batch_features, 0.2, 51).numpy()
        batch_predictions = existing_model.predict(batch_selected_features)

        for i, pred in enumerate(batch_predictions):
            if pred >= 0.5:  # Threshold for classificaton #For config file
                real_cells.append(batch_coords[i])
    print(f"real_cells_dest: {real_cells_dest}, is directory? {os.path.isdir(real_cells_dest)}")
            # Save real cell coordinates
    with open(real_cells_dest, mode='w', newline='') as file:
        writer = csv.writer(file)
        writer.writerow(['min x', 'max x', 'min y', 'max y'])
        writer.writerows(real_cells)

"""Main"""
#Extraction
batch_size = p["batch_size"]  #from configuration file
real_cells_dest = os.path.join(output_dir, "real_cells.csv")
wsi_img = readIMG(wsi_img_path)
csv_file = os.path.join(output_dir, "coords_cells.csv")  # Ensure correct CSV file path
process_images_from_csv(csv_file, wsi_img, batch_size=96, real_cells_dest=real_cells_dest)
print("Notebook 2 has run successfully")
#Load the saved predictions of the images
#predictions = np.load('/content/drive/MyDrive/MSc/Research/useful_notebook/tryfile1_featuresANDlabels/labels.npy')